<!DOCTYPE html><html lang="fr"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>C’est quoi un LLM ? Comment fonctionnent les moteurs de ChatGPT, Gemini et autres ? - ooo.so</title><meta name="description" content="Derrière ChatGPT, Google Gemini, Microsoft CoPilot, Meta AI et autres, il y&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://ooo.so/cest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html"><link rel="alternate" type="application/atom+xml" href="https://ooo.so/feed.xml"><link rel="alternate" type="application/json" href="https://ooo.so/feed.json"><meta property="og:title" content="C’est quoi un LLM ? Comment fonctionnent les moteurs de ChatGPT, Gemini et autres ?"><meta property="og:image" content="https://ooo.so/media/posts/13/qu-est-ce-qu-un-llm-cover.webp"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:site_name" content="ooo.so"><meta property="og:description" content="Derrière ChatGPT, Google Gemini, Microsoft CoPilot, Meta AI et autres, il y&hellip;"><meta property="og:url" content="https://ooo.so/cest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html"><meta property="og:type" content="article"><link rel="stylesheet" href="https://ooo.so/assets/css/style.css?v=de2971726a7ed7fff6666295e4ab5e35"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://ooo.so/cest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html"},"headline":"C’est quoi un LLM ? Comment fonctionnent les moteurs de ChatGPT, Gemini et autres ?","datePublished":"2025-03-28T23:48","dateModified":"2025-03-31T02:08","image":{"@type":"ImageObject","url":"https://ooo.so/media/posts/13/qu-est-ce-qu-un-llm-cover.webp","height":630,"width":1200},"description":"Derrière ChatGPT, Google Gemini, Microsoft CoPilot, Meta AI et autres, il y&hellip;","author":{"@type":"Person","name":"Tarik","url":"https://ooo.so/authors/tarik/"},"publisher":{"@type":"Organization","name":"Tarik"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="post-template"><div class="container"><header class="header" id="js-header"><a href="https://ooo.so/" class="logo">ooo.so</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li><a href="https://ooo.so/" title="Home" target="_self">Home</a></li><li class="has-submenu"><span class="is-separator" title="Intelligence Artificielle" aria-haspopup="true">Sujets</span><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://ooo.so/tags/" target="_self">Tous les sujets ...</a></li><li><a href="https://ooo.so/tags/ai/" target="_self">Intelligence Artificielle</a></li><li><a href="https://ooo.so/tags/llm/" target="_self">LLM</a></li><li><a href="https://ooo.so/tags/youtube/" target="_self">Youtube</a></li><li><a href="https://ooo.so/tags/open-source/" target="_self">Open Source</a></li><li><a href="https://ooo.so/tags/technologie/" target="_self">Technologie</a></li><li><a href="https://ooo.so/tags/tutoriel/" target="_self">Tutoriels</a></li></ul></li><li class="active-parent has-submenu"><span class="is-separator" title="Posts" aria-haspopup="true">Posts</span><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://ooo.so/youtube-sans-pubs-gratuit-et-legal.html" target="_self">Youtube Sans Pubs sur Smartphone</a></li><li><a href="https://ooo.so/mais-comment-diable-internet-sur-mobile-de-starlink-peut-il-fonctionner.html" target="_self">Internet pas Sat sur Mobile</a></li><li><a href="https://ooo.so/first-post.html" target="_self">Top IA</a></li><li class="active"><a href="https://ooo.so/cest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html" target="_self">C&#x27;est quoi un LLM</a></li><li><a href="https://ooo.so/chatgpt-son-fonctionnement-son-potentiel-et-ses-dangers-le-guide-ultime-pour-tout-comprendre.html" target="_self">ChatGPT</a></li><li><a href="https://ooo.so/installer-un-chatgpt-sur-pc-ou-mac-voici-le-guide-ultime-pour-tous.html" target="_self">ChatGPT en Local</a></li><li><a href="https://ooo.so/vos-images-prennent-la-parole-la-startup-de-xavier-niel-lance-moshivis.html" target="_self">MoshiVis</a></li><li><a href="https://ooo.so/open-source-en-2025-11-logiciels-incontournables-a-adopter-pour-se-liberer-des-geants-du-web.html" target="_self">11 logiciels open source</a></li></ul></li><li class="has-submenu"><span class="is-separator" aria-haspopup="true">Apps/ Saas</span><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://ooo.so/compartaeur-de-forfaits-mobile.html" target="_self">Comparateur de Forfaits Mobiles</a></li></ul></li><li class="has-submenu"><span class="is-separator" aria-haspopup="true">Projets</span><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://ooo.so/web-browser.html" target="_self">Web Browser</a></li><li><a href="https://ooo.so/mapsmix.html" target="_self">Maps Mix</a></li></ul></li><li class="has-submenu"><span class="is-separator" title="Auteurs" aria-haspopup="true">Auteurs</span><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://ooo.so/authors/tarik/" target="_self">Tarik Bensakhria</a></li><li><a href="https://cvdesignr.com/p/67c1aaecf0052" target="_self">A propos</a></li><li><a href="https://ooo.so/" target="_self">Tous les auteurs ...</a></li></ul></li></ul></nav></header><main class="post"><article class="content wrapper"><header class="hero"><p class="content__meta">Par <a href="https://ooo.so/authors/tarik/" rel="author" title="Tarik">Tarik</a> Published on <time datetime="2025-03-28T23:48">vendredi, 28 mars 2025</time></p><h1 class="content__title">C’est quoi un LLM ? Comment fonctionnent les moteurs de ChatGPT, Gemini et autres ?</h1></header><figure class="content__featured-image post__image--wide"><img src="https://ooo.so/media/posts/13/qu-est-ce-qu-un-llm-cover.webp" srcset="https://ooo.so/media/posts/13/responsive/qu-est-ce-qu-un-llm-cover-xs.webp 300w, https://ooo.so/media/posts/13/responsive/qu-est-ce-qu-un-llm-cover-sm.webp 480w, https://ooo.so/media/posts/13/responsive/qu-est-ce-qu-un-llm-cover-md.webp 768w, https://ooo.so/media/posts/13/responsive/qu-est-ce-qu-un-llm-cover-lg.webp 1024w, https://ooo.so/media/posts/13/responsive/qu-est-ce-qu-un-llm-cover-xl.webp 1360w, https://ooo.so/media/posts/13/responsive/qu-est-ce-qu-un-llm-cover-2xl.webp 1600w, https://ooo.so/media/posts/13/responsive/qu-est-ce-qu-un-llm-cover-sm2.webp 375w" sizes="(max-width: 1600px) 100vw, 1600px" loading="eager" height="630" width="1200" alt=""></figure><div class="content__entry"><div class="chapo has-text-weight-semibold mb-5"><div><strong>Derrière ChatGPT, Google Gemini, Microsoft CoPilot, Meta AI et autres, il y a ce qu’on appelle les LLM, pour « large language models », ou grands modèles de langage en français. Ce sont en fait les moteurs des chatbots textuels d’IA, ceux qui apprennent et qui « comprennent » ce qu’on leur dit.</strong></div></div><figure class="wp-block-image aligncenter size-medium"><a href="https://images.frandroid.com/wp-content/uploads/2023/11/llm.jpg" target="_blank" rel="noopener" class="article-content__figure"><figure class="wp-image-1866661 wp-image wp-image"><img src="https://c0.lestechnophiles.com/images.frandroid.com/wp-content/uploads/2023/11/llm.jpg?resize=1200&amp;key=0b51958a&amp;watermark" sizes="(max-width: 1200px) 100vw, 1200px" srcset="https://images.frandroid.com/wp-content/uploads/2023/11/llm-1200x675.jpg 1200w, https://images.frandroid.com/wp-content/uploads/2023/11/llm-768x432.jpg 768w, https://images.frandroid.com/wp-content/uploads/2023/11/llm-928x522.jpg 928w, https://images.frandroid.com/wp-content/uploads/2023/11/llm-300x169.jpg 300w" alt="" width="1200" height="675" loading="eager" data-is-external-image="true"></figure></a></figure><p>Qu’est-ce qui se cache derrière <a href="https://ooo.so/installer-un-chatgpt-sur-pc-ou-mac-voici-le-guide-ultime-pour-tous.html" target="_blank" rel="noopener noreferrer">ChatGPT</a> ? Comment fonctionnent les <a href="https://www.enseignementsup-recherche.gouv.fr/fr/intelligence-artificielle-de-quoi-parle-t-91190" target="_blank" rel="noopener noreferrer">intelligences artificielles</a> génératives textuelles ? Avec l’émergence des outils d’IA, nombreuses sont les questions autour de leur fonctionnement mystérieux.</p><p>En fait, derrière ChatGPT, il y a ce qu’on appelle un « <em>LLM</em> »… Un quoi ?</p><p><span id="ca-veut-dire-quoi-llm" class="index" tabindex="-1" data-title="Ça veut dire quoi « LLM » ?"></span></p><h2 id="h-qu-est-ce-que-ca-veut-dire-llm-en-ia" class="wp-block-heading">Qu’est-ce que ça veut dire « <em>LLM</em> » en IA ?</h2><p>LLM est l’acronyme de l’expression anglaise « <em>L</em><em>arge Language Model</em> ». On pourrait la traduire en français par « <em>grand modèle de langage</em> ». Il s’agit de modèles de langage qui possèdent généralement au moins un milliard de paramètres. En français, on peut aussi les nommer « <em>modèles massifs de langage</em> » et les désigner avec l’acronyme « <em>MML</em> ».</p><p class="shortcode-container see-more"><span class="has-text-weight-bold has-text-body">Pour aller plus loin</span><br><a href="https://ooo.so/chatgpt-son-fonctionnement-son-potentiel-et-ses-dangers-le-guide-ultime-pour-tout-comprendre.html">ChatGPT : son fonctionnement, son potentiel et ses dangers… Le guide ultime pour tout comprendre</a></p><p><span id="comment-fonctionnent-les-llm" class="index" tabindex="-1" data-title="Comment fonctionnent les LLM ?"></span></p><h2 id="h-comment-fonctionne-un-large-language-model-le-moteur-des-intelligences-artificielles" class="wp-block-heading">Comment fonctionne un large language model, le moteur des intelligences artificielles ?</h2><p>Un LLM, c’est en réalité un réseau de neurones artificiels profonds, soit un logiciel dont la conception est inspirée du fonctionnement des neurones biologiques. Chaque neurone informatique (ou formel) possède des entrées (qui correspondent aux dendrites) ainsi qu’une sortie (correspondant à l’axone). À l’aide de règles précises qu’on lui indique, le neurone formel peut transformer une entrée en une sortie. Ces neurones artificiels sont associés en réseaux selon différents types de connexions (certaines auront plus de poids, ou exécuteront une tâche plus régulièrement).</p><p> </p><figure class="wp-block-image size-full"><a href="https://images.frandroid.com/wp-content/uploads/2023/11/schema-reseau-de-neurones-1.jpeg" target="_blank" rel="noopener" class="article-content__figure"><figure class="wp-image-1875705 wp-image"><img src="https://images.frandroid.com/wp-content/uploads/2023/11/schema-reseau-de-neurones-1.jpeg" sizes="auto, (max-width: 596px) 100vw, 596px" srcset="https://images.frandroid.com/wp-content/uploads/2023/11/schema-reseau-de-neurones-1.jpeg 596w, https://images.frandroid.com/wp-content/uploads/2023/11/schema-reseau-de-neurones-1-300x200.jpeg 300w" alt="" width="596" height="397" loading="lazy" data-is-external-image="true"></figure></a><figcaption class="wp-element-caption">Schéma simplifié d’un réseau de neurones // Source : Wikipédia</figcaption></figure><p>La force de ce système de réseau de neurones, c’est que comme chez l’animal, il peut « <em>apprendre</em> » de lui-même : c’est le <a href="https://fr.wikipedia.org/wiki/Apprentissage_automatique" target="_blank" rel="noopener noreferrer"><em>machine learning</em></a>. Mais on peut aller plus loin avec l’apprentissage automatique (appelé <em>deep learning</em> en anglais), qui possède un avantage de taille : il ne nécessite pas qu’un être humain rentre « <em>à la main</em> » tout ce que la machine doit apprendre. De quoi décupler la puissance finale du système.</p><figure class="wp-block-image size-medium"><a href="https://images.frandroid.com/wp-content/uploads/2023/11/structure-neurone-artificiel.jpeg" target="_blank" rel="noopener" class="article-content__figure"><figure class="wp-image-1875719 wp-image"><img src="https://images.frandroid.com/wp-content/uploads/2023/11/structure-neurone-artificiel-1200x569.jpeg" sizes="auto, (max-width: 1200px) 100vw, 1200px" srcset="https://images.frandroid.com/wp-content/uploads/2023/11/structure-neurone-artificiel-1200x569.jpeg 1200w, https://images.frandroid.com/wp-content/uploads/2023/11/structure-neurone-artificiel-768x364.jpeg 768w, https://images.frandroid.com/wp-content/uploads/2023/11/structure-neurone-artificiel-928x440.jpeg 928w, https://images.frandroid.com/wp-content/uploads/2023/11/structure-neurone-artificiel-300x142.jpeg 300w" alt="" width="1200" height="569" loading="lazy" data-is-external-image="true"></figure></a><figcaption class="wp-element-caption">Schéma de la structure d’un neurone artificiel // Source : Wikipédia</figcaption></figure><p>Pour faire apprendre à un LLM, il faut lui donner du texte, beaucoup de texte. Pour cela, on peut simplement prendre <a href="https://www.frandroid.com/telecharger/apps/wikipedia" target="_blank" rel="noopener">Wikipédia</a> : <a href="https://wikimediafoundation.org/fr/about/press/" target="_blank" rel="noopener">selon la Wikimedia Foundation</a>, l’encyclopédie en ligne compte plus de 58 millions d’articles en près de 300 langues. Il existe également des ensembles de données textuelles spécialisés dans l’entraînement de LLM, qui sont parfois <em>open source</em>.</p><p>La qualité de l’apprentissage dépend aussi de ce qu’on appelle l’étiquetage des données. Dans le domaine de l’intelligence artificielle, l’étiquetage est le fait de donner la réponse à une tâche demandée à partir de données déterminées. Pour du texte, l’étiquetage peut être par exemple de qualifier un texte de « <em>factuel</em> » dans son style, de « <em>familier</em> » dans son vocabulaire, ou bien « <em>d’injurieux</em> » dans ce qu’il dit.</p><p>Lorsqu’on partage du texte en entrée à un chatbot, il est transformé en nombres par le LLM, puis analysé, et une sortie est formée en nombres également, avant d’être convertie en texte en sortie. Ces nombres, on les appelle en fait des vecteurs. Comme le précise <a href="https://www.01net.com/actualites/modele-de-langage-intelligence-artificielle-explications-definition.html" target="_blank" rel="noopener"><em>01net</em></a>, ce sont ces nombres qui permettent d’instaurer des scores de proximité entre eux. Plus le nombre possède de chiffres, plus le modèle est complexe, et donc performant. C’est une sorte de mathématisation du texte qui s’effectue et c’est ce qui permet à un algorithme d’imiter le langage humain.</p><h3 id="h-ce-qu-a-change-l-architecture-transformer-au-nbsp-deep-learning" class="wp-block-heading">Ce qu’a changé l’architecture Transformer au <em>deep learning</em></h3><p>C’est en 2017 qu’un changement technologique va bouleverser le monde de l’intelligence artificielle : la création de l’architecture Transformer. Elle résulte d’une longue combinaison de procédés techniques, avec des travaux datant de nombreuses années.</p><p>Un « <em>transformeur</em> », c’est un modèle d’apprentissage profond, principalement taillé pour ce qu’on appelle le traitement automatique des langues. Là où les réseaux neuronaux traditionnels comme les réseaux de neurones récurrents traitent une requête en entrée de manière séquentielle (du début d’une phrase à la fin), le transformeur peut paralléliser cette entrée, afin de considérablement réduire les temps d’entraînement. Réduire les temps d’entraînement, c’est avoir plus d’entraînements pour un coût de fonctionnement de serveurs égal et aller plus loin.</p><figure class="wp-block-image size-full"><a href="https://images.frandroid.com/wp-content/uploads/2023/11/1066px-architecture-dun-transfor.jpg" target="_blank" rel="noopener" class="article-content__figure"><figure class="wp-image-1876489 wp-image"><img src="https://images.frandroid.com/wp-content/uploads/2023/11/1066px-architecture-dun-transfor.jpg" sizes="auto, (max-width: 1066px) 100vw, 1066px" srcset="https://images.frandroid.com/wp-content/uploads/2023/11/1066px-architecture-dun-transfor.jpg 1066w, https://images.frandroid.com/wp-content/uploads/2023/11/1066px-architecture-dun-transfor-768x691.jpg 768w, https://images.frandroid.com/wp-content/uploads/2023/11/1066px-architecture-dun-transfor-928x835.jpg 928w, https://images.frandroid.com/wp-content/uploads/2023/11/1066px-architecture-dun-transfor-300x270.jpg 300w" alt="" width="1066" height="959" loading="lazy" data-is-external-image="true"></figure></a><figcaption class="wp-element-caption">Schéma du fonctionnement de l’architecture Transformeur // Source : Wikipédia</figcaption></figure><p>Un bon exemple de l’intérêt de cette architecture est raconté par le philosophe Daniel Andler dans son ouvrage <em>Intelligence artificielle, intelligence humaine : la double énigme</em>. Pour la phrase « <em>j’ai un frère, il est architecte</em> », « <em>frère</em> » et « <em>il</em> » désignent la même personne : la construction de la phrase est simple et les deux termes se suivent. Mais dans la phrase « <em>quand mon frère s’est fâché avec son associé, je lui ai avoué qu’il ne m’avait jamais plu</em> », « <em>mon frère</em> » et « <em>lui</em> » sont éloignés. C’est là que le Transformer utilise un mécanisme d’« <em>auto-attention</em> », qui prend en compte « <em>ces effets à distance du contexte</em> ». C’est ce mécanisme qui permet de prendre un contexte dans le traitement d’une entrée. Un mécanisme qui fonctionne sur deux principes : les « <em>masks</em> » et les « <em>tokens</em> ».</p><p>Pour le premier, il y a deux types de masques :</p><ul class="wp-block-list"><li>Les « <em>filtres de causalité</em> » qui vont modifier le poids de certains vecteurs en fonction du contexte donné par la phrase ;</li><li>Les « <em>filtres de padding</em> » qui font en sorte que toutes les phrases aient la même longueur mathématique (autant de nombres en elles), en ajoutant des mots inutiles et non pris en compte dans le traitement.</li></ul><p>Ce sont les <em>tokens</em> qui permettent aux réseaux neuronaux de « <em>comprendre</em> » chaque mot en les traitant, pas seulement les uns à la suite des autres. Ils attribuent aussi des liens entre les mots.</p><h3 id="h-les-premiers-vrais-modeles-de-langage-nbsp-gpt-et-bert" class="wp-block-heading">Les premiers « <em>vrais</em> » modèles de langage : GPT et BERT</h3><p>Deux LLM, qu’on peut considérer comme des pionniers, ont été publiés en 2018 à quelques semaines d’écart. Le premier, c’est GPT, pour Generative Pre-Trained Transformer d’<a href="https://www.lesechos.fr/tech-medias/intelligence-artificielle/de-la-philanthrope-a-la-course-aux-profits-la-folle-histoire-dopenai-2148127" target="_blank" rel="noopener noreferrer">OpenAI</a>. Le second, c’est BERT de DeepMind (<a href="https://www.lebigdata.fr/google-deepmind" target="_blank" rel="noopener noreferrer">qui appartient à Google</a>). Grâce à l’architecture Transformer, ils se sont révélés être des révolutions dans les LLM.</p><figure class="wp-block-image size-medium"><a href="https://images.frandroid.com/wp-content/uploads/2023/11/schema-entrainement-bert-deepmind.jpeg" target="_blank" rel="noopener" class="article-content__figure"><figure class="wp-image-1876501 wp-image"><img src="https://images.frandroid.com/wp-content/uploads/2023/11/schema-entrainement-bert-deepmind-1200x490.jpeg" sizes="auto, (max-width: 1200px) 100vw, 1200px" srcset="https://images.frandroid.com/wp-content/uploads/2023/11/schema-entrainement-bert-deepmind-1200x490.jpeg 1200w, https://images.frandroid.com/wp-content/uploads/2023/11/schema-entrainement-bert-deepmind-768x314.jpeg 768w, https://images.frandroid.com/wp-content/uploads/2023/11/schema-entrainement-bert-deepmind-928x379.jpeg 928w, https://images.frandroid.com/wp-content/uploads/2023/11/schema-entrainement-bert-deepmind-300x123.jpeg 300w" alt="" width="1200" height="490" loading="lazy" data-is-external-image="true"></figure></a><figcaption class="wp-element-caption">Schéma du fonctionnement de l’entraînement de BERT // Source : « BERT : Pre-training of Deep Bidirectional Transformers for Language Understanding »</figcaption></figure><p>Ils sont très bons en compréhension du langage naturel ainsi qu’en génération de texte. Ils peuvent réaliser des tâches simplement en leur demandant de manière textuelle : « <em>résumer</em> », « <em>traduire</em> », « <em>rédiger</em> ». C’est aussi l’une des premières fois que des modèles de langage ne sont pas pré-entraînés pour une tâche particulière, mais pour tout un ensemble, dont on ne connaît même pas l’étendue.</p><h3 id="h-pourquoi-parle-t-on-de-parametres-pour-un-modele-de-langage" class="wp-block-heading">Pourquoi parle-t-on de « <em>paramètres</em> » pour un modèle de langage ?</h3><p>Lorsqu’on parle de LLM, on parle beaucoup de « <em>paramètres</em> » : plus il y en a, plus un modèle serait puissant, performant. C’est vrai, mais ce n’est pas une vérité générale. En fait, les réseaux neuronaux contiennent plusieurs nœuds, sur plusieurs couches. Comme l’explique <a href="https://aws.amazon.com/fr/what-is/large-language-model/" target="_blank" rel="noopener">Amazon Web Services</a>, « <em>chaque nœud de chaque couche est connecté à tous les nœuds de la couche suivante</em> ». Chacun a un poids et un écart différent : ce sont ces poids et ces écarts qui sont en fait les paramètres d’un LLM. C’est pour cela qu’on peut « <em>facilement</em> » en avoir des dizaines de milliards. Ce qu’offrent les paramètres, c’est la capacité à davantage capturer de nuances et de complexités dans le langage. Cela permet de prendre en compte des données en entrée plus importantes et des sorties qui le sont aussi. Néanmoins, plus un LLM va loin dans la « <em>compréhension</em> », plus il lui faut de paramètres (de manière exponentielle) et de puissance (de serveurs). Durant la phase d’entraînement, ce sont les poids et les écarts qui sont ajustés de manière itérative.</p><p><span id="a-quoi-servent-les-llm" class="index" tabindex="-1" data-title="À quoi servent les LLM ?"></span></p><h2 id="h-a-quoi-servent-les-nbsp-large-language-models" class="wp-block-heading">À quoi servent les <em>large language models</em> ?</h2><p>La grande force des LLM, c’est précisément qu’ils n’ont pas d’usage précis, puisqu’ils n’ont pas été entraînés sur une capacité en particulier. Leur fonctionnement neuronal fait qu’ils sont entraînés à la prédiction d’une suite probable en fonction d’une entrée donnée (une séquence de mots).</p><div class="ultimedia_cntr" data-nosnippet=""><div data-vendor="iab:343"> </div><div class="ultimedia_plyr"> </div></div><figure class="wp-block-image size-medium"><a href="https://images.frandroid.com/wp-content/uploads/2023/06/openai-chatgpt-scaled.jpg" target="_blank" rel="noopener" class="article-content__figure"><figure class="wp-image-1720939 wp-image"><img src="https://images.frandroid.com/wp-content/uploads/2023/06/openai-chatgpt-1200x900.jpg" sizes="auto, (max-width: 1200px) 100vw, 1200px" srcset="https://images.frandroid.com/wp-content/uploads/2023/06/openai-chatgpt-1200x900.jpg 1200w, https://images.frandroid.com/wp-content/uploads/2023/06/openai-chatgpt-768x576.jpg 768w, https://images.frandroid.com/wp-content/uploads/2023/06/openai-chatgpt-928x696.jpg 928w, https://images.frandroid.com/wp-content/uploads/2023/06/openai-chatgpt-300x225.jpg 300w" alt="" width="1200" height="900" loading="lazy" data-is-external-image="true"></figure></a><figcaption class="wp-element-caption">Emiliano Vittoriosi sur Unsplash</figcaption></figure><p>Si vous demandez à ChatGPT de vous raconter une histoire, un conte pour enfants par exemple, il va probablement démarrer par « <em>Il était une fois</em> », puisque c’est très classique. Ensuite, la probabilité de ce qui arrive après est « <em>dans un royaume</em> », ou « <em>une princesse</em> », quelque chose comme cela. En réalité, <strong>les LLM ne « <em>comprennent</em> » pas les textes</strong> sur lesquels ils ont été entraînés ni ce qu’on leur écrit. <strong>Les LLM sont simplement des systèmes statistiques, appliqués à la linguistique</strong>. Ils ne déterminent pas que des mots, mais également toute la syntaxe, la conjugaison et la ponctuation de ce qui fait les langues.</p><p>Ce qui fait qu’un LLM va être performant dépend de plusieurs facteurs. Tout d’abord, il y a le nombre des paramètres. Plus ils sont nombreux, plus le modèle de langage pourra prendre de facteurs en compte dans sa réponse, ce qui fera qu’elle sera plus précise. D’ailleurs, on découvre certaines capacités en agrandissant le modèle, en augmentant le nombre de paramètres. Comme l’écrit Daniel Andler, « <em>une propriété émerge à partir d’une certaine taille, sans que l’on sache aujourd’hui pourquoi.</em> » La capacité de traduction, la simulation des émotions ou de l’humour en sont quelques exemples.</p><figure class="wp-block-image size-medium"><a href="https://images.frandroid.com/wp-content/uploads/2023/02/microsoft-bing-chatgpt-1.jpg" target="_blank" rel="noopener" class="article-content__figure"><figure class="wp-image-1607973 wp-image"><img src="https://images.frandroid.com/wp-content/uploads/2023/02/microsoft-bing-chatgpt-1-1200x968.jpg" sizes="auto, (max-width: 1200px) 100vw, 1200px" srcset="https://images.frandroid.com/wp-content/uploads/2023/02/microsoft-bing-chatgpt-1-1200x968.jpg 1200w, https://images.frandroid.com/wp-content/uploads/2023/02/microsoft-bing-chatgpt-1-768x619.jpg 768w, https://images.frandroid.com/wp-content/uploads/2023/02/microsoft-bing-chatgpt-1-928x748.jpg 928w, https://images.frandroid.com/wp-content/uploads/2023/02/microsoft-bing-chatgpt-1-300x242.jpg 300w" alt="" width="1200" height="968" loading="lazy" data-is-external-image="true"></figure></a><figcaption class="wp-element-caption">Quelques exemples de question à poser à ChatGPT via Bing // Source : Capture d’écran</figcaption></figure><p>Cela dépend par ailleurs de la puissance de calcul consacrée au fonctionnement du LLM. Enfin, il y a la qualité des données qui lui ont été fournies en entrée par l’utilisateur. En clair, plus votre demande à ChatGPT est précise, plus le LLM derrière aura de contexte et d’informations pour vous apporter une réponse précise. La qualité des données comprend également la largeur de l’éventail de données qu’il a eu pour s’entraîner, ainsi que la qualité de leur étiquetage. Plus l’étiquetage a été poussé, plus le modèle peut « <em>interpréter</em> » les données d’entraînement et celles qu’on lui fournit lors de la requête.</p><p> </p><h2 id="h-quels-sont-les-grands-modeles-de-langage-qui-existent" class="wp-block-heading"></h2></div><footer class="content__footer"><div class="content__last-updated">Cet Article a été mis à jour le lundi, 31 mars 2025</div><div class="content__footer__col"><ul class="content__tag"><li><a href="https://ooo.so/tags/ai/">AI</a></li><li><a href="https://ooo.so/tags/llm/">LLM</a></li></ul><div class="content__share"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fooo.so%2Fcest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html" class="js-share facebook" aria-label="Partager avec Facebook" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://ooo.so/assets/svg/svg-map.svg#facebook"/></svg> </a><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fooo.so%2Fcest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html&amp;via=ooo.so&amp;text=C%E2%80%99est%20quoi%20un%20LLM%E2%80%89%3F%20Comment%20fonctionnent%20les%20moteurs%20de%20ChatGPT%2C%20Gemini%20et%20autres%E2%80%89%3F" class="js-share twitter" aria-label="Partager avec Twitter" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://ooo.so/assets/svg/svg-map.svg#twitter"/></svg> </a><a href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fooo.so%2Fcest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html&amp;media=https%3A%2F%2Fooo.so%2Fmedia%2Fposts%2F13%2Fqu-est-ce-qu-un-llm-cover.webp&amp;description=C%E2%80%99est%20quoi%20un%20LLM%E2%80%89%3F%20Comment%20fonctionnent%20les%20moteurs%20de%20ChatGPT%2C%20Gemini%20et%20autres%E2%80%89%3F" class="js-share pinterest" aria-label="[MISSING TRANSLATION] Partager avec Pinterest" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://ooo.so/assets/svg/svg-map.svg#pinterest"/></svg> </a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fooo.so%2Fcest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html" class="js-share linkedin" aria-label="Partager avec LinkedIn" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://ooo.so/assets/svg/svg-map.svg#linkedin"/></svg> </a><a href="https://api.whatsapp.com/send?text=C%E2%80%99est%20quoi%20un%20LLM%E2%80%89%3F%20Comment%20fonctionnent%20les%20moteurs%20de%20ChatGPT%2C%20Gemini%20et%20autres%E2%80%89%3F https%3A%2F%2Fooo.so%2Fcest-quoi-un-llm-comment-fonctionnent-les-moteurs-de-chatgpt-gemini-et-autres.html" class="js-share whatsapp" aria-label="Partager avec WhatsApp" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://ooo.so/assets/svg/svg-map.svg#whatsapp"/></svg></a></div></div><nav class="content__nav"><div class="content__nav__prev">Post précédant<h5><a href="https://ooo.so/immobilier-pappers-immobilier-revolutionne-lacces-aux-prix-du-marche-grace-a-lopen-data.html" class="invert" rel="prev">Immobilier : Pappers Immobilier révolutionne l’accès aux prix du marché grâce à l’open data</a></h5></div><div class="content__nav__next">Post Suivant<h5><a href="https://ooo.so/installer-un-chatgpt-sur-pc-ou-mac-voici-le-guide-ultime-pour-tous.html" class="invert" rel="next">Installer un ChatGPT sur PC ou Mac : voici le guide ultime pour tous</a></h5></div></nav><div class="content__bio"><div><h3><a href="https://ooo.so/authors/tarik/" class="invert" title="Tarik">Tarik</a></h3></div></div><div class="content__related"><h3 class="u-h5">Posts Liés</h3><div class="content__related__wrap"><figure><a href="https://ooo.so/mais-comment-diable-internet-sur-mobile-de-starlink-peut-il-fonctionner.html"><img src="https://ooo.so/media/posts/6/responsive/Starlink-en-Haiti-1-xs.jpg" loading="lazy" alt=""></a><figcaption><h4><a href="https://ooo.so/mais-comment-diable-internet-sur-mobile-de-starlink-peut-il-fonctionner.html" class="invert">Comment internet sur mobile de Starlink peut il fonctionner</a></h4><time datetime="2025-03-26T23:23">mercredi, 26 mars 2025</time></figcaption></figure></div></div></footer></article><div class="comments-area wrapper"></div></main><footer class="footer"><div class="footer__copyright">© Tarik Bensakhria</div><div class="footer__social"></div></footer></div><script defer="defer" src="https://ooo.so/assets/js/scripts.min.js?v=4268bfae06e330d473c424d50f09abda"></script><script>window.publiiThemeMenuConfig={mobileMenuMode:'sidebar',animationSpeed:300,submenuWidth: 'auto',doubleClickTime:500,mobileMenuExpandableSubmenus:true,relatedContainerForOverlayMenuSelector:'.navbar'};</script><script>/*<![CDATA[*/var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};/*]]>*/</script></body></html>